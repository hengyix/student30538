---
title: "Problem Set 2 Answer"
format: pdf
---
1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*\ HX_\_\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/1-zzHx762odGlpVWtgdIC55vqF-j3gqdAp6Pno1rIGK0/edit)**"  \*\*\_HX\_\*\* (1 point)
3. Late coins used this pset: \*\*\_1\_*\* Late coins left after submission: \*\*\_3\_*\*
4. Knit your `ps2.qmd` to make `ps2.pdf`. 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
5. Push  `ps2.qmd` and `ps2.pdf` to your github repo. It is fine to use Github Desktop.

```{python}
#| warning: false
import pandas as pd
import altair as alt
import os
alt.renderers.enable('png')

# Read in the csv file
# Warning message is suppressed for output clarity.
data = pd.read_csv(
    'problem_sets/ps2/data/parking_tickets_one_percent.csv', 
    index_col=[0]
    )
df = pd.DataFrame(data)
```

## Data Cleaning continued
***Q1***
```{python}
# Define the function to count NAs
def count_na(df):
    labels = []  
    na_counts = [] 
    for label, content in df.items():
        count = content.isna().sum()
        labels.append(label)
        na_counts.append(count)
    result_dict = {'Variable': labels, 'NA Count': na_counts}
    result_df = pd.DataFrame.from_dict(result_dict)
    return result_df


# Conduct a test
df_test = pd.DataFrame({
    'A': [1, 2, None, None],
    'B': [1, 2, 3, 4],
    'C': [1, 'Apple', 3, None]
})
print(df_test, '\n')
print(count_na(df_test), '\n')

print('So the function works.\nApplying to our dataset:', '\n')
print(count_na(df))
```

***Q2***
<br>

The zipcode, notice_level and hearing_disposition are missing much more frequently than others, probably because of the way data was collected. According to the dictionary, zipcode is the ZIP code associated with the vehicle registration. If the registration information is unclear or incomplete, this field might be left empty. notice_level describes the type of notice the city has sent a motorist. If no notice was sent, this field would be blank. Similarly, hearing_disposition represents the outcome of a hearing. If the ticket was not contested, this field would be blank. <br>

In conclusion, these three variables contain more NAs than average because of their data entry styles. These fields are filled only if certain conditions are met, such as ticket got contested. Other variables that capture essential information, such as ticket numbers and issue dates, are routinely collected with each ticket issued.
Thus, they are more likely to be NA than others. <br>

***Q3***
```{python}
df_Q3 = df[df['violation_description'].str.contains('NO CITY STICKER', na=False)]
print(df_Q3['violation_code'].unique()) # Ordered by first apperance in dataset
```

By inspection, we know that 0976170 and 0964125C are extremely rare cases in the dataset. Here we ignore these two values. 
Old violation code: 0964125; New violation code: 0964125B.
\newpage
***Q4***<br>

Accoding to the articles, citations for not having a required vehicle sticker rose from $120 to $200. So we have the cost under old violation code: $120; under new code: $200. In the dataset, we refer to the variable of fine_level1_amount.
```{python}
# For '0964125' 
print(df[df['violation_code'] == '0964125']['fine_level1_amount'].unique())
```
```{python}
# For '0964125B' 
print(df[df['violation_code'] == '0964125B']['fine_level1_amount'].unique())
# '0964125C' ignored as instructed.
```
The result above aligns with the article. To be more specific, the cost of an initial offense under 0964125 was $120, and the cost of an initial offense under 0964125B was $200.

## Revenue increase from 'missing city sticker' tickets
***Q1***
```{python}
# Unify the codes with 000
df_unified = df.copy()
df_unified =  df_unified.replace('0964125', '000')
df_unified =  df_unified.replace('0964125B', '000')
df_unified = df_unified[df_unified['violation_code'] == '000']
# Extract year-month and count
df_unified['issue_date'] = pd.to_datetime(
df_unified['issue_date'])
df_unified['issue_y_m'] = df_unified['issue_date'].dt.strftime('%Y-%m')
grouped_date = df_unified.groupby('issue_y_m')
Q1_count = grouped_date.size().reset_index(name='count')
print(Q1_count.head(10))

# Aggregate by year and month
chart_1 = alt.Chart(Q1_count).mark_area(
    interpolate='step-after',
    line=True
).encode(
    alt.X(
        'issue_y_m:T', 
        title='Time',
        axis=alt.Axis(format='%Y-%m')
        ), 
    alt.Y(
        'count:Q', 
        title='Count'
        )
).properties(
    width=500,
    title='Missing City Sticker Tickets by Month'
)

chart_1
```

***Q2***
```{python}
# Find the date of cost increase
df_new_code = df_unified[df_unified['fine_level1_amount'] == 200]
print(df_new_code['issue_date'].iloc[0])
print('So we know the date of cost increase was 2012-02-25.')
cost_increase_date = '2012-02-25'

# Add a vertical line at 2012-02-25
rule = alt.Chart(
    pd.DataFrame(
        {
            'cost_increase_date': [cost_increase_date], 
            'label': ['Cost Increase']
            }
        )
    ).mark_rule(
    color='red',
    strokeDash=[8, 4]
).encode(
    x='cost_increase_date:T',
    tooltip=['label']
)

# Label for cost increase
text = alt.Chart(
    pd.DataFrame(
        {
            'cost_increase_date': [cost_increase_date], 
            'label': ['2012-02-25']
            }
        )
    ).mark_text(
    align='left',
    baseline='bottom',
    dx=-20,
    dy=150,
    color='red'
).encode(
    x='cost_increase_date:T',
    text='label'
)

chart_1 + rule + text
```
[Help page](https://altair-viz.github.io/user_guide/marks/rule.html#)
(https://altair-viz.github.io/user_guide/marks/rule.html#) <br>

***Q3***
```{python}
# Filter out data in 2011
df_2011 = df_unified[df_unified['issue_date'].dt.year == 2011]
tickets_2011 = df_2011.shape[0]
print(f'{tickets_2011} no city sticker tickets were issued in 2011.')
# We assume the same amount later on
revenue_increase = tickets_2011 * (200 - 120) * 100 # Dataset is one percent
print(revenue_increase)
```
So they should have expected $15464000 of revenue increase, which is approximately 15.5 million US dollars per year.
\newpage
***Q4***
```{python}
# Before price increased
df_before_increase = df_unified[df_unified['fine_level1_amount'] == 120]
df_before_paid = df_before_increase[df_before_increase['ticket_queue'] == 'Paid']
paid_rate_before = df_before_paid.shape[0] / df_before_increase.shape[0]
print(f'Before increase, the repayment rate was {paid_rate_before}.')

# Filter out data in 2013
df_2013 = df_unified[df_unified['issue_date'].dt.year == 2013]
df_2013_paid = df_2013[df_2013['ticket_queue'] == 'Paid']
paid_rate_2013 = df_2013_paid.shape[0] / df_2013.shape[0]
print(f'In the calendar year after increase, repayment rate was {paid_rate_2013}.')

print('So we see a drop in repayment rate in tickets after the price was increased.')
print('From around 54% to 41%.')

# Under repayment rate of 41%
# We still assume 1933 tickets per year
revenue_increase_rate = (
    tickets_2011 * paid_rate_2013 * 200 - tickets_2011 * paid_rate_before * 120
    ) * 100 
print(revenue_increase_rate)
```
Under the new repayment rates, the change in revenue should have been about approximately 3.1 million US dollars per year.

***Q5***
```{python}
# Again use the dataframe aggregated by month and year
# We already have total tickets for each month-year in the previous question
# Now we only need to count paid tickets
df_paid = df_unified[df_unified['ticket_queue'] == 'Paid']
group_paid = df_paid.groupby('issue_y_m')
df_paid_count = group_paid.size().reset_index(name='count_paid')

# Combine with the count of total tickets
Q5_count = pd.merge(df_paid_count, Q1_count)
# Calculate repayment rates in a new column
Q5_count['repayment_rate'] = Q5_count['count_paid'] / Q5_count['count']
print(Q5_count.head(10)) # Ready for plotting

chart2 = alt.Chart(Q5_count).mark_line().encode(
    alt.X('issue_y_m:T', title='Time', axis=alt.Axis(format='%Y-%m')),
    alt.Y('repayment_rate:Q', title='Repayment Rates')
).properties(
    width=500,
    title='Repayment Rates of No City Sticker Tickets by Month'
)

# The verticle line and annotation have been set in Question 2.
chart2 + rule + text
```

From the plot, we can see a downward trend in repayment rates of no city sticker tickets over time, after the new policy was introduced. The repayment rates kept fluctuating, but after the price went up, repayment rates were in general significantly lower than before. The average level under the new policy was apparently below that under the old code. Moreover, toward the end of our dataset, there was an ongoing sharp decline in repayment rates. The rates dropped to extremely low by 2018.
<br>

This indicates the need to balance repayment rates and penalty amounts, in order to boost the government revenue. <br>

***Q6***
```{python}
# 000 represents no city sticker
df_Q6 = df.copy()
df_Q6 = df_Q6.replace('0964125', '000')
df_Q6 = df_Q6.replace('0964125B', '000')

# Filter out records before policy change
df_Q6['issue_date'] = pd.to_datetime(df_Q6['issue_date'])
df_Q6 = df_Q6[df_Q6['issue_date'] < '2012-02-25']

# Calculate repayment rates
grouped_code = df_Q6.groupby('violation_code')
df_code_count = grouped_code.size().reset_index(name='total_tickets')
# Those never paid are ignored here, they are missed in filter and merge
# Never paid tickets are of no relevance
df_Q6_paid = df_Q6[df_Q6['ticket_queue'] == 'Paid']
grouped_code_paid = df_Q6_paid.groupby('violation_code')
df_code_count_paid = grouped_code_paid.size().reset_index(name='paid_tickets')

Q6_count = pd.merge(df_code_count, df_code_count_paid)
Q6_count['repayment_rates'] = Q6_count['paid_tickets'] / Q6_count['total_tickets']
# We have both ticket counts and repayment rates 

# Explore the dataset: tickets issued
Q6_count = Q6_count.sort_values(by='total_tickets', ascending=False)
print(Q6_count.head(15))
```

The suggested three violation types would be 0964190 ('EXPIRED METER OR OVERSTAY'), 0964040B ('STREET CLEANING'), and 0976160F ('EXPIRED PLATES OR TEMPORARY REGISTRATION'). <br>

This is because we need to seek for both high total number of tickets and high repayment rates. We use the multiplication of these two parameters as measure, which is paid_tickets. 
From the dataframe Q6_count as shown above, we could tell that these three violation codes have relatively higher total_ticket counts and repayment rates. They have the most paid tickets in 2011.
```{python}
# To boost revenue, the amount of tickets should be large to make a difference.
# By inspection, we set the bar of 5000 total tickets in 2011 here.
Q6_count = Q6_count[Q6_count['total_tickets'] > 5000]

chart_3 = alt.Chart(Q6_count).mark_circle(size=200).encode(
    alt.X('total_tickets:Q', title='Tickets Issued').scale(zero=False),
    alt.Y('repayment_rates:Q', title='Repayment Rates').scale(zero=False),
    color='violation_code:N').properties(
    width=500,
    title='Ticket Counts and Repayment Rates of Top Violation Types in 2011'
)

chart_3
```

The plot supports the argument by providing a contrast among different violation codes. The three dots we chose, 0964190, 0976160F, 0964040B, are positioned either high on the y-axis, indicating higher repayment rates, or far to the right on the x-axis, representing a larger number of tickets issued, or both. 
In this plot, we could find 0964190, 0976160F, 0964040B might be the three best choices. 
\newpage

## Headlines and sub-messages
***Q1***
```{python}
grouped_description = df.groupby('violation_description')

# Description and repayment rate
total_count = grouped_description.size().reset_index(name='total_tickets')

df_paid = df[df['ticket_queue'] == 'Paid'].copy()
grouped_des_paid = df_paid.groupby('violation_description')
paid_count = grouped_des_paid.size().reset_index(name='paid_tickets')

# Those left out in df_paid are violation never paid
all_violations = df['violation_description'].unique()
paid_violations = df_paid['violation_description'].unique()
unpaid_violations = [item for item in all_violations if item not in paid_violations]
# Fill in with 0 paid tickets for these three types
unpaid_dict = {
    'violation_description': unpaid_violations, 
    'paid_tickets': [0, 0, 0]
    }
unpaid_df = pd.DataFrame(unpaid_dict)
paid_count = pd.concat([paid_count, unpaid_df], ignore_index=True)

description_payment = pd.merge(
    total_count, paid_count, 
    on='violation_description'
    )
description_payment['repayment_rates'] = description_payment['paid_tickets'] / \
                                         description_payment['total_tickets']

# Description and average fine amount
description_price = grouped_description['fine_level1_amount'].mean()
description_price = description_price.reset_index(name='avg_price')

description_summary = pd.merge(description_payment, description_price)

# Sort by frequency and print most common 5
Q_3_1 = description_summary.sort_values('total_tickets', ascending=False)
Q_3_1 = Q_3_1[['violation_description', 'repayment_rates', 'avg_price']]
print(Q_3_1.head(5))
```

***Q2***
```{python}
# Filter out types more than 100 times 
Q_3_2 = description_summary[description_summary['total_tickets'] > 99]

# Exclude the extreme value with high fine amount
print(Q_3_2.sort_values('avg_price', ascending=False)[0: 5])
print('So we need to exclude NO CITY STICKER VEHICLE OVER 16,000 LBS.')
Q_3_2 = Q_3_2[Q_3_2['violation_description'] != 'NO CITY STICKER VEHICLE OVER 16,000 LBS.']

# Scatter plot
chart_4 = alt.Chart(Q_3_2).mark_point().encode(
    alt.X('avg_price:Q', title='Average Fine Amount'),
    alt.Y('repayment_rates:Q', title='Repayment Rates')
).properties(
    title='Average Fine Amount Versus Repayment Rates'
)

chart_4
```
Headline: In general, average fine amount and repayment rates are negatively correlated. As average fine amount goes up, repayment rates tend to decrease, among top violation types. <br>

Submessages: Most top violation types are priced under $100 at the initial stage, with repayment rates ranging from 50% to 80%. The lowest repayment rate is around 20%, and the lowest average price is over $20. The highest repayment rate reaches about 85%, with an average fine around $50. And as average fine amount increases, the spread of repayment rates becomes more dispersed at first, and then more condensed.

```{python}
chart_5 = alt.Chart(Q_3_2).mark_bar().encode(
    alt.X(
        'avg_price:Q', 
        title='Average Fine Amount', 
        bin=alt.BinParams(maxbins=20)
        ),
    alt.Y(
        'repayment_rates:Q', 
        title='Repayment Rates', 
        bin=alt.BinParams(maxbins=20)
        ),
    alt.Color('count()')
).properties(
    title='Average Fine Amount Versus Repayment Rates'
)

chart_5
```
Headline: Most of frequent violation types are priced between $20 and $80, with repayment rates ranging from 55% and 85%. <br>

Submessages: Repayment rates tend to decrease with increase in average fine amount when we focus on most frequent violation types. Besides, as average penalty amount goes up, the range of repayment rates gets wider abd then narrower, finally concentrated at a more consistent yet lower level. 

```{python}
chart_6 = alt.Chart(Q_3_2).mark_boxplot().encode(
    alt.X(
        'avg_price:Q', 
        title='Average Fine Amount', 
        bin=alt.BinParams(maxbins=20)
        ),
    alt.Y(
        'repayment_rates:Q', 
        title='Repayment Rates'
        )
).properties(
    title='Average Fine Amount Versus Repayment Rates'
)

chart_6 
```
Headline: With the increase in average price, the spread of repayment rates widens and then narrows. <br>

Submessages: There is a concave trend in the median of repaymemt rates as average fine amount goes up. Among top violation types, few records exist when the average price exceeds $160. And in general, repayment rates decrease when average fine amount increases. <br>

***Q3***<br>

The first plot, scatter plot, would be the best choice because it shows every single violation type, in a very direct and straightforward way. Readers can follow the dots and identify the genreal trend at first sight without additional information. They could easily tell that as average fine amount goes up, repayment ratea tend to decline. <br>

By contrast, other two plots require some effort in understanding the meaning of squares and dots or some knowledge of statistical concepts such as quartile and bins.
<br>

## Understanding the structure of the data and summarizing it 
***Q1***
```{python}
# Filter out records unpaid yet price not doubled
df_unpaid = df[df['ticket_queue'] != 'Paid']
df_undoubled = df_unpaid[
    df_unpaid['fine_level2_amount'] != df_unpaid['fine_level1_amount'] * 2
]
print('This dataframe is not empty.')
print('So this argument does not hold for all violations.')

# Fetch violation types with at least 100 citations
Q_4_1 = df_undoubled.groupby(
    'violation_description'
    ).size().reset_index(name='citation')
type_undoubled = Q_4_1['violation_description'][Q_4_1['citation'] > 99].to_list()

df_undoubled = df_undoubled[
    df_undoubled['violation_description'].isin(type_undoubled)
    ]

df_diff = df_undoubled.groupby('violation_description')\
    [['fine_level1_amount', 'fine_level2_amount']].mean().reset_index()
df_diff['price_increase'] = \
    df_diff['fine_level2_amount'] - df_diff['fine_level1_amount']
print('Each ticket increase if unpaid: ')
print(df_diff[['violation_description', 'price_increase']])
```
\newpage
***Q2*** <br>

![Tree_Plot_1](Tree_Plot_1.jpg)
If someone contests their ticket and is found not liable, we have notice_level = 'VIOL' and ticket_queue = 'Dismissed'.<br>

***Q3***
```{python}
#| warning: false
# Pick top 10 descriptions and name all others as Other
Q_4_3 = Q_3_2.sort_values('total_tickets', ascending=False).copy()
Q_4_3['violation_description'][10:] = 'Other'

chart_a = alt.Chart(Q_4_3).mark_point().encode(
    alt.X('avg_price:Q', title='Average Fine Amount'),
    alt.Y('repayment_rates:Q', title='Repayment Rates'),
    alt.Color('violation_description:N').scale(scheme='paired')
).properties(
    title='Average Fine Amount Versus Repayment Rates'
)

chart_a
```
```{python}
# Common label and common color
category_dict = {
    "Parking": [
        "20'OF CROSSWALK", "NO PARK IN PRIVATE LOT", "NO PARK IN PUBLIC LOT", 
            "PARK OUTSIDE METERED SPACE", "PARK ALLEY", 
        "DOUBLE PARKING OR STANDING", "DOUBLE PARKING OR STANDING", 
            "DOUBLE PARKING OR STANDING", 
        "PARK OR BLOCK ALLEY", "PARK/STAND ON BICYCLE PATH", 
            "PARK OR STAND IN BUS/TAXI/CARRIAGE STAND",
        "PARK OR STAND IN VIADUCT/UNDERPASS", "PARK OR STAND ON CITY PROPERTY", \
            "PARK OR STAND ON CROSSWALK",
        "PARK OR STAND ON PARKWAY", "PARK OR STAND ON SIDEWALK",\
             "PARKING/STANDING PROHIBITED ANYTIME",
        "WITHIN 15' OF FIRE HYDRANT", "RESIDENTIAL PERMIT PARKING",\
             "INDUSTRIAL PERMIT PARKING", 
        "CURB LOADING ZONE", "NO STANDING/PARKING TIME RESTRICTED", \
            "PARK IN CITY LOT WHEN CLOSED", \
                "SMOKED/TINTED WINDOWS PARKED/STANDING",
        "WRONG DIRECTION OR 12'' FROM CURB"
    ],
    "Sticker and Registration": [
        "NO CITY STICKER OR IMPROPER DISPLAY", \
            "NO CITY STICKER VEHICLE UNDER/EQUAL TO 16,000 LBS.", \
                "IMPROPER DISPLAY OF CITY STICKER", \
                    "EXPIRED PLATE OR TEMPORARY  REGISTRATION", \
            "REAR AND FRONT PLATE REQUIRED", \
        "REAR PLATE REQUIRED MOTORCYCLE/TRAILER", 
        "EXPIRED PLATES OR TEMPORARY REGISTRATION", \
            "MISSING/NONCOMPLIANT FRONT AND/OR REAR PLATE", \
                "NONCOMPLIANT PLATE(S)",
                "EXPIRED PLATE OR TEMPORARY REGISTRATION"
    ],
    "Safe Driving and Traffic Rules": [
        "ABANDONED VEH. FOR 7 DAYS OR INOPERABLE", \
            "DOUBLE PARKING OR STANDING", "SAFETY BELTS REQUIRED", \
                "STOP SIGN OR TRAFFIC SIGNAL", \
                    "STAND, PARK, OR OTHER USE OF BUS LANE", \
                        "3-7 AM SNOW ROUTE", "SNOW ROUTE: 2'' OF SNOW OR MORE", \
            "SPECIAL EVENTS RESTRICTION", "STREET CLEANING", \
                "STREET CLEANING OR SPECIAL EVENT", "RUSH HOUR PARKING"
    ],
    "Large Vehicle Restrictions": [
        "TRUCK OR SEMI-TRAILER PROHIBITED", \
            "TRUCK TRAILOR/SEMI/TRAILER PROHIBITED", \
            "TRUCK,MOTOR HOME, BUS BUSINESS STREET", \
                "TRUCK,RV,BUS, OR TAXI RESIDENTIAL STREET"
    ],
    "Vehicle Maintenance and Safety": [
        "LAMPS BROKEN OR INOPERABLE", "REAR PLATE LIT AND LEGIBLE FOR 50'",\
            "RED REAR LAMP REQUIRED VISIBLE 500'", \
            "TWO HEAD LAMPS REQUIRED VISIBLE 1000'", \
                "WINDOWS MISSING OR CRACKED BEYOND 6", \
                    "HAZARDOUS DILAPIDATED VEHICLE", \
                        "OBSTRUCTED OR IMPROPERLY TINTED WINDOWS", \
                             "BURGLAR ALARM SOUNDING OVER 4 MINUTES",\
                                "HAZARDOUS DILAPITATED VEHICLE"
    ],
    "Obstruction and Improper Use": [
        "BLOCK ACCESS/ALLEY/DRIVEWAY/FIRELANE", \
            "OBSTRUCT ROADWAY", \
                "OUTSIDE DIAGONAL MARKINGS", \
                    "PARK VEHICLE SOLE PURPOSE OF DISPLAYING FOR SALE", \
                        "DISABLED CURB CUT", "DISABLED PARKING ZONE"
    ],
    "Payment and Meter Violations": [
        "EXP. METER NON-CENTRAL BUSINESS DISTRICT", \
            "EXPIRED METER CENTRAL BUSINESS DISTRICT", \
                "EXPIRED METER OR OVERSTAY", \
                    "NON PYMT/NON-COM VEH PARKED IN COM LOADING ZONE"
    ]
}

reverse_dict = {violation: category for category, violations in \
    category_dict.items() for violation in violations}

Q_4_4 = Q_3_2.copy()
Q_4_4['category'] = Q_4_4['violation_description'].map(reverse_dict)

chart_b = alt.Chart(Q_4_4).mark_point().encode(
    alt.X('avg_price:Q', title='Average Fine Amount'),
    alt.Y('repayment_rates:Q', title='Repayment Rates'),
    alt.Color('category:N').scale(scheme='accent')
).properties(
    title='Average Fine Amount Versus Repayment Rates'
)



chart_b
```
## Extra Credit
```{python}
#| warning: false
code_description = df.groupby(
    ['violation_code', 'violation_description']
    ).size().reset_index(name='records')
multi_code = code_description.groupby('violation_code').\
    size().reset_index(name='descriptions')
codes = multi_code['violation_code'][multi_code['descriptions'] > 1].to_list()
code_description = \
    code_description[code_description['violation_code'].isin(codes)]

max_description = code_description.loc[
    code_description.groupby('violation_code')['records'].idxmax(), 
    ['violation_code', 'violation_description']
].reset_index(drop=True)
print('Codes with multiple descriptions: top description')
print(max_description, '\n')

# Find top three
code_records = code_description.groupby('violation_code')\
    .apply(lambda g: g['records'].sum())
print(code_records)
print('The three codes with most observations: 0964040B, 0976160A, 0976160B')

```